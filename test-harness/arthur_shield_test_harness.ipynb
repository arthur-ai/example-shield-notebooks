{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efac5cfd-12ec-4038-b9f7-1522ebd0e3e5",
   "metadata": {},
   "source": [
    "# Arthur Shield Test Harness\n",
    "\n",
    "The code below can be used to perform a test of the PII, Prompt Injection, Sensitivity, Toxicity, and Hallucination detection capabilities of Arthur Shield.\n",
    "\n",
    "### Pre-Requisites: \n",
    "- You will need to configure which checks you would like to perform within Arthur Shield. See https://shield.docs.arthur.ai/docs/rule-configuration-guide\n",
    "- You will need to compile a CSV file containing test prompts for each of the rules you would like to evaluate. You can reference the main template CSV in this folder for formatting, and use it to create your own list of prompts. The columns your input CSV should include are as follows (case-sensitive):\n",
    "    * *Non-hallucination checks*:\n",
    "        * *id* - A unique ID for the prompt\n",
    "        * *prompt* - The text you are sending to Shield that you would like to check\n",
    "        * *flag* - Which flag you expect this prompt to trigger. Must choose one of the following (ENUM): pii, prompt_injection, sensitive_data, toxicity, control\n",
    "    * *Hallucination checks*:\n",
    "        * *id* - A unique ID for the prompt\n",
    "        * *response* - The response from the LLM to be checked - should be mocked/pre-populated for this test\n",
    "        * *context* - The context which the response is supposed to be referencing\n",
    "        * *flag* - Which flag you expect this prompt to trigger. Must choose one of the following (ENUM): hallucination, control\n",
    "- **Notes for creating control prompts/responses**:\n",
    "  * *For non-hallucination checks*: In the `prompt` column, enter a simple prompt which will not violate any of the rules\n",
    "  * *For hallucination checks*: Provide context in the `context` column. In the `response` column, provide a response that only contains information that can be found within the context. Example below:\n",
    "    * `response`: \"The main export of Country X is textiles.\"\n",
    "    * `context`: \"Country X is known for its strong textile industry, which accounts for the majority of its exports.\"\n",
    "    * `flag`: control\n",
    "- Please aim to have at least 15 (and preferably more) prompts for each of the rules you would like to test in order to gather accurate analysis results, including controls\n",
    "\n",
    "### Output:\n",
    "This harness will output 2 CSVs: \n",
    "- Test output file containing info on the prompt, Shield flags, and latency\n",
    "- Metrics file containing various evaluation performance metrics for each of the Shield rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f346b-0779-4a53-ae23-6d9c6f22cbee",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "Fill out the config below with the details specific to your Shield instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a34cf7-fc8c-4209-8d8f-f932509bc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import shutil\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests \n",
    "from datetime import datetime\n",
    "\n",
    "from os.path import abspath, join\n",
    "import sys\n",
    "\n",
    "utils_path = abspath(join('..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "from shield_utils import setup_env, get_task, create_task_rule, archive_task\n",
    "\n",
    "load_dotenv()\n",
    "SHIELD_ENDPOINT = os.getenv('SHIELD_ENDPOINT', 'https://<your-shield-instance>') # Do not include the slash on the end\n",
    "SHIELD_API_KEY = os.getenv('SHIELD_API_KEY', '<your-shield-api-key>')\n",
    "\n",
    "MAIN_INPUT_FILE = 'data/hr_prompt_input.csv' # Change this to whatever your input file name is\n",
    "MAIN_OUTPUT_FILE = 'output/shield_output_hr.csv'\n",
    "METRICS_FILE = 'output/shield_test_metrics_hr.csv'\n",
    "\n",
    "shield_headers = {\n",
    "    'Authorization': f'Bearer {SHIELD_API_KEY}'\n",
    "}\n",
    "\n",
    "setup_env(base_url=SHIELD_ENDPOINT, api_key=SHIELD_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473e252-857e-4516-8f41-d1ce9713ab12",
   "metadata": {},
   "source": [
    "You'll start by setting up a test task containing all the rules that you would like to run the harness for. This test task contains all the default rules you have set up for your Shield instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d6bc3-011d-48ef-88e5-6bd33846f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ENDPOINT = f\"{SHIELD_ENDPOINT}/api/v2/task\"\n",
    "payload = {\"name\": \"test-harness\"}\n",
    "\n",
    "response = requests.post(TASK_ENDPOINT, headers=shield_headers, json=payload).json()\n",
    "task_id = response[\"id\"]\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ac373-d5ea-4114-a396-f2bb4bc91c7a",
   "metadata": {},
   "source": [
    "Review the response output from the previous cell to see which rules are associated with the task you just created. If you would like to delete those rules and/or add additional rules for testing, you can use the cells below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20572e-9b63-4885-a895-ef6bf40d7258",
   "metadata": {},
   "source": [
    "#### Delete existing rule(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29239b-026f-4549-ba66-0e79b22ba123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete one rule from the test-harness task\n",
    "def delete_one_rule(task_id, rule_id):\n",
    "    endpoint = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/rules/{rule_id}\"\n",
    "    return requests.delete(endpoint, headers=shield_headers)\n",
    "\n",
    "# Delete all rules from the test-harness task\n",
    "def delete_all_rules(task_id):\n",
    "    get_endpoint = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}\"\n",
    "    response = requests.get(get_endpoint, headers=shield_headers).json()\n",
    "    rule_ids=[]\n",
    "    for rule in response[\"rules\"]:\n",
    "        rule_ids.append(rule[\"id\"])\n",
    "    for rule_id in rule_ids:\n",
    "        delete_one_rule(task_id, rule_id)\n",
    "\n",
    "# Run either of the above functions to delete whichever rules you'd like to delete\n",
    "#delete_one_rule(task_id, <insert_rule_id>)\n",
    "delete_all_rules(task_id)\n",
    "\n",
    "# See the updated task configuration\n",
    "get_task(task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135f476-a03f-479b-9bf6-fd40b93155c3",
   "metadata": {},
   "source": [
    "#### Add new rules \n",
    "See https://shield.docs.arthur.ai/docs/rule-configuration-guide for rule setup instructions. Templates are provided below, but you can modify each of these rules as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa996d-3618-4941-a2c8-689d00f267ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pii = {\n",
    "  \"name\": \"Test PII Rule\",\n",
    "  \"type\": \"PIIDataRule\",\n",
    "  \"apply_to_prompt\": True,\n",
    "  \"apply_to_response\": False,\n",
    "  \"config\": {}\n",
    "}\n",
    "prompt_injection = {\n",
    "  \"name\": \"Test Prompt Injection Rule\",\n",
    "  \"type\": \"PromptInjectionRule\",\n",
    "  \"apply_to_prompt\": True,\n",
    "  \"apply_to_response\": False\n",
    "}\n",
    "toxicity = {\n",
    "  \"name\": \"Test Toxicity Rule\",\n",
    "  \"type\": \"ToxicityRule\",\n",
    "  \"apply_to_prompt\": True,\n",
    "  \"apply_to_response\": False\n",
    "}\n",
    "hallucination = {\n",
    "  \"name\": \"Test HallucinationV2 Rule\",\n",
    "  \"type\": \"ModelHallucinationRuleV2\",\n",
    "  \"apply_to_prompt\": False,\n",
    "  \"apply_to_response\": True\n",
    "}\n",
    "# You can reconfigure the sensitive data rule to your needs by providing positive/negative examples as shown below\n",
    "sensitive_data = { \n",
    "    \"name\": \"Test Sensitive Data Password Rule\",\n",
    "    \"type\": \"ModelSensitiveDataRule\",\n",
    "    \"apply_to_prompt\": True,\n",
    "    \"apply_to_response\": False,\n",
    "    \"config\": {\n",
    "        \"examples\": [\n",
    "            {\n",
    "                \"example\": \"Hi, Your password 5d9kpQDXRiVf for our online therapy portal has been set successfully.\",\n",
    "                \"result\": True\n",
    "            },\n",
    "            {\n",
    "                \"example\": \"Mr. Conroy's password, h78WwcpT3s6B has leaked online.\",\n",
    "                \"result\": True\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"During this time, your login credentials Remington31 and VXBDni7EO5od will be reset..\",\n",
    "                \"result\": True\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"Hey Agnes, your login details for the upcoming clinical trial are as follows: IP: 73ac:d53c:f2bb:94a5:86f3:1dca:e1ec:2b4e, Password: WlBi79j58UsW.\",\n",
    "                \"result\": True\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"Can't access database for financial report. Hassie34's password last updated to mWGhCVGWuB8o.\",\n",
    "                \"result\": True\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"Linnea_OConnell, please submit your final Psychopharmacology thesis for review by 11/32.\",\n",
    "                \"result\": False\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"Dear client, thank you for your payment of NT$200 for our acupuncture services.\",\n",
    "                \"result\": False\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"Surely, Nolan and Sons would not want to restrict its healthcare services to people less than 91 years old years of age in the 40753 region?\",\n",
    "                \"result\": False\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"The name tag for the new staff member, Angel has arrived. You will find it in the Apt. 634.\",\n",
    "                \"result\": False\n",
    "            },\n",
    "                    {\n",
    "                \"example\": \"Your password has been reset.\",\n",
    "                \"result\": False\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6258f-29ee-4fde-ac20-8fc4e1124a7f",
   "metadata": {},
   "source": [
    "Once you've configured the rule settings, choose which rules you would like to test and add them to the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb802b0-b620-4056-a8e5-afed30b00825",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_to_test = [pii, prompt_injection, sensitive_data, toxicity, hallucination]\n",
    "\n",
    "for rule in rules_to_test:\n",
    "    create_task_rule(task_id, rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73fc95-e4e1-44f4-ba03-d15f42651784",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_task(task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421941e3-78c0-49d7-85f6-23dbc82da6f7",
   "metadata": {},
   "source": [
    "## i. Non-Hallucination Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd710ae-df76-4532-ab9d-ad294ffbe902",
   "metadata": {},
   "source": [
    "### Support Functions\n",
    "\n",
    "Shield's response schema can be found on the API docs: https://\\<your-shield-instance>/docs#/Default%20Validation/default_validate_prompt_api_v2_validate_prompt_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789476f-c80d-497e-b72f-6b1906adda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIELD_VAL_ENDPOINT = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/validate_prompt\"\n",
    "\n",
    "def get_firewall_flags(resp_dict):\n",
    "    # Determines which rules (PII, Prompt Injection, Toxicity, Sensitivity) were flagged\n",
    "    flags = []\n",
    "    for rule in resp_dict[\"rule_results\"]:\n",
    "        if rule[\"result\"] == \"Fail\":\n",
    "            if rule[\"rule_type\"] in [\"ModelHallucinationRuleV2\", \"ModelHallucionationRuleV3\"] and \"hallucination\" not in flags:\n",
    "                # Only used for responses - does not check for other flags\n",
    "                flags.append(\"hallucination\")\n",
    "                break\n",
    "            elif rule[\"rule_type\"] == \"PIIDataRule\" and \"pii\" not in flags:\n",
    "                flags.append(\"pii\")\n",
    "            elif rule[\"rule_type\"] == \"PromptInjectionRule\" and \"prompt_injection\" not in flags:\n",
    "                flags.append(\"prompt_injection\")\n",
    "            elif rule[\"rule_type\"] == \"ToxicityRule\" and \"toxicity\" not in flags:\n",
    "                flags.append(\"toxicity\")\n",
    "            elif rule[\"rule_type\"] == \"ModelSensitiveDataRule\" and \"sensitive_data\" not in flags:\n",
    "                flags.append(\"sensitive_data\")\n",
    "    return flags\n",
    "\n",
    "def get_gt_output_match(row):\n",
    "    # Returns True if GT label matches Shield flags and False otherwise\n",
    "    if row[\"ground_truth\"] == \"control\": \n",
    "        return False if row[\"shield_response\"] else True\n",
    "    else:\n",
    "        return True if row[\"ground_truth\"] in row[\"shield_response\"] else False\n",
    "    \n",
    "\n",
    "def get_pii_triggers(shield_response):\n",
    "    # Isolate the text which triggered the PII rule to fire\n",
    "    output = []\n",
    "    for rule in shield_response[\"rule_results\"]:\n",
    "        if rule[\"rule_type\"]== \"PIIDataRule\" and rule[\"result\"]==\"Fail\":\n",
    "            for flag in rule[\"details\"][\"pii_entities\"]:\n",
    "                output.append({\n",
    "                    \"string_trigger\": flag[\"span\"],\n",
    "                    \"flag_type\": flag[\"entity\"]\n",
    "                })\n",
    "    return output\n",
    "\n",
    "def get_shield_response(row):\n",
    "    # Calls Shield API and updates the row dictionary based upon the results from Shield\n",
    "    shield_start = datetime.now()\n",
    "    response = requests.post(SHIELD_VAL_ENDPOINT, headers=shield_headers, json={\"prompt\": row[\"prompt\"]})\n",
    "    shield_end = datetime.now()\n",
    "    row[\"latency_ms\"] = int((shield_end - shield_start).microseconds/1000)\n",
    "    row[\"shield_response\"] = get_firewall_flags(response.json())\n",
    "    row[\"gt_output_match\"] = get_gt_output_match(row)\n",
    "    row[\"sub_flags\"] = get_pii_triggers(response.json()) if \"pii\" in row[\"shield_response\"] else None\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54eb91f-eb2e-4c52-a744-7d017c57285b",
   "metadata": {},
   "source": [
    "### Generate Output File\n",
    "\n",
    "The output file generated will contain: \n",
    "  * *id* - The ID of the corresponding input file prompt\n",
    "  * *prompt* - The prompt that was passed\n",
    "  * *ground_truth* - The flag that was expected\n",
    "  * *shield_response* - The flag that Shield raised\n",
    "  * *test_passed* - Whether the ground truth label matches the flag that Shield raised (True or False)\n",
    "  * *sub-flags* - (For PII) Which sentences were flagged and which PII flag was raised\n",
    "  * *latency_ms* - Latency of Shield call in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84df830-dd5c-4b22-a774-7f8255acc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_name = \"output\"\n",
    "if os.path.exists(output_folder_name):\n",
    "    shutil.rmtree(output_folder_name)\n",
    "os.makedirs(output_folder_name)\n",
    "\n",
    "with open(MAIN_INPUT_FILE, newline='') as infile:\n",
    "    reader= csv.DictReader(infile)\n",
    "    with open(MAIN_OUTPUT_FILE, 'w', newline='') as outfile:\n",
    "        # List of columns for the output file\n",
    "        fieldnames = [\n",
    "            \"id\",\n",
    "            \"prompt\",\n",
    "            \"ground_truth\",\n",
    "            \"shield_response\",\n",
    "            \"gt_output_match\",\n",
    "            \"sub_flags\",\n",
    "            \"latency_ms\"\n",
    "        ]\n",
    "        writer= csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for row in reader:\n",
    "            out_row = {\n",
    "                \"id\": row[\"id\"],\n",
    "                \"ground_truth\": row[\"flag\"],\n",
    "                \"prompt\": row[\"prompt\"]\n",
    "                }\n",
    "\n",
    "            out_row = get_shield_response(out_row)\n",
    "            writer.writerow(out_row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133da1da-4287-4585-b688-11ef3a0fd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(MAIN_OUTPUT_FILE)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906f76e-2136-470d-bcf0-b27c700b4dd9",
   "metadata": {},
   "source": [
    "## ii. Hallucination Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d582a19-d93b-4cce-8323-f23ee0f9266a",
   "metadata": {},
   "source": [
    "The hallucination checks hit a different endpoint and require a slightly different input format, so we run those checks separately here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665a268-efc2-4fd9-a3e8-57215b0b90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "HALLUCINATION_INPUT = 'data/hr_response_input.csv' # Change this to whatever your input file name is \n",
    "HALLUCINATION_OUTPUT = 'output/shield_output_hallucination_hr.csv'\n",
    "\n",
    "SHIELD_RESP_ENDPOINT = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/validate_response/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1876a7-1304-4cf9-aa2e-0ed1693e49d9",
   "metadata": {},
   "source": [
    "### Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1400d-16ab-4c11-9490-e91b6bb73654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claims(response):\n",
    "    # Extracts the claims from the Shield flag \n",
    "    for rule in response[\"rule_results\"]:\n",
    "        if rule[\"rule_type\"] not in [\"ModelHallucinationRuleV2\", \"ModelHallucinationRuleV3\"]:\n",
    "            continue\n",
    "        else:\n",
    "            if rule[\"result\"] == \"Pass\":\n",
    "                return []\n",
    "            else:\n",
    "                return rule[\"details\"][\"claims\"]\n",
    "\n",
    "def get_inference_id(prompt):\n",
    "    # Conduct an initial Shield call to get an inference ID for the response endpoint\n",
    "    response = (requests.post(\n",
    "        SHIELD_VAL_ENDPOINT, \n",
    "        headers=shield_headers, \n",
    "        json={\"prompt\": prompt})).json()\n",
    "    return str(response[\"inference_id\"])\n",
    "        \n",
    "def get_hallucination_shield_response(row):\n",
    "    # Calls Shield API and updates the row dictionary based upon the results from Shield\n",
    "    resp_endpoint = SHIELD_RESP_ENDPOINT + get_inference_id(\"null\")\n",
    "    shield_start = datetime.now()\n",
    "    response = requests.post(\n",
    "        resp_endpoint, \n",
    "        headers=shield_headers, \n",
    "        json={\"response\": row[\"llm_response\"], \"context\": row[\"context\"]}\n",
    "    )\n",
    "    shield_end = datetime.now()\n",
    "    row[\"latency_ms\"] = int((shield_end - shield_start).microseconds/1000)\n",
    "    row[\"shield_response\"] = get_firewall_flags(response.json())\n",
    "    row[\"claims\"] = get_claims(response.json())\n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8147d-f600-4287-b0b4-0c48dd62f716",
   "metadata": {},
   "source": [
    "### Generate Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab0ca3-d1bf-426a-a94e-3ecdafeb62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HALLUCINATION_INPUT, newline='') as infile:\n",
    "    reader= csv.DictReader(infile)\n",
    "    with open(HALLUCINATION_OUTPUT, 'w', newline='') as outfile:\n",
    "        # List of columns for the output file\n",
    "        fieldnames = [\n",
    "            \"id\",\n",
    "            \"context\",\n",
    "            \"llm_response\",\n",
    "            \"ground_truth\",\n",
    "            \"shield_response\",\n",
    "            \"claims\",\n",
    "            \"latency_ms\"\n",
    "        ]\n",
    "        writer= csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for row in reader:\n",
    "            out_row = {\n",
    "                \"id\": row[\"id\"],\n",
    "                \"llm_response\": row[\"response\"],\n",
    "                \"context\": row[\"context\"],\n",
    "                \"ground_truth\": row[\"flag\"]\n",
    "                }\n",
    "\n",
    "            out_row = get_hallucination_shield_response(out_row)\n",
    "            writer.writerow(out_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5988b7-9ad4-40ae-a4ee-ffee545e018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(HALLUCINATION_OUTPUT)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7593c-b3ac-4d3b-b529-a728dfa79bc5",
   "metadata": {},
   "source": [
    "## iii. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da0e84-18c5-4516-97e4-e60bb60c511b",
   "metadata": {},
   "source": [
    "The metrics file generated will contain:\n",
    "  * True Positive Count\n",
    "  * False Positive Count\n",
    "  * Precision\n",
    "  * Recall\n",
    "  * Specificity\n",
    "  * Miss Rate\n",
    "  * False Positive Rate\n",
    "  * F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbdd0f-9a68-459f-9fe8-b2a00f215757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_row(data_row, precision=3):\n",
    "    return [round(item, precision) if isinstance(item, (float, int)) else item for item in data_row]\n",
    "\n",
    "def create_metrics_dict(metric_name):\n",
    "    if metric_name == \"hallucination\":\n",
    "        hdf= pd.read_csv(HALLUCINATION_OUTPUT)\n",
    "        metrics = {\n",
    "            \"tp\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"hallucination\") & (hdf['shield_response'].apply(lambda x: metric_name in x))\n",
    "            ].shape[0],\n",
    "            \"fp\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"control\") & (hdf['shield_response'].apply(lambda x: metric_name in x))\n",
    "            ].shape[0],\n",
    "            \"fn\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"hallucination\") & (hdf['shield_response'].apply(lambda x: metric_name not in x))\n",
    "            ].shape[0],\n",
    "            \"tn\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"control\") & (hdf['shield_response'].apply(lambda x: metric_name not in x))\n",
    "            ].shape[0]\n",
    "        }\n",
    "    else:\n",
    "        df = pd.read_csv(MAIN_OUTPUT_FILE)\n",
    "        metrics = {\n",
    "            \"tp\": df[(df['gt_output_match']==True) & (df['ground_truth']==metric_name)].shape[0],\n",
    "            \"fp\": df[(df['ground_truth']!=metric_name) & (df['shield_response'].apply(lambda x: metric_name in x))].shape[0],\n",
    "            \"fn\": df[(df['ground_truth']==metric_name) & (df['gt_output_match']==False)].shape[0],\n",
    "            \"tn\": df[(df['ground_truth']!=metric_name) & (df['shield_response'].apply(lambda x: metric_name not in x))].shape[0]\n",
    "        }\n",
    "    try:\n",
    "        metrics[\"prec\"] = metrics[\"tp\"]/(metrics[\"tp\"]+metrics[\"fp\"])\n",
    "    except: \n",
    "        metrics[\"prec\"] = \"N/A\"\n",
    "    try:\n",
    "        metrics[\"recall\"] = metrics[\"tp\"]/(metrics[\"tp\"]+metrics[\"fn\"])\n",
    "    except:\n",
    "        metrics[\"recall\"] = \"N/A\"\n",
    "    return metrics\n",
    "\n",
    "def run_analysis(checks=[\"pii\", \"prompt_injection\", \"toxicity\", \"sensitive_data\", \"hallucination\"]):\n",
    "    # Runs analysis on the selected checks. Runs on all by default\n",
    "    with open(METRICS_FILE, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        metrics = []\n",
    "        for check in checks:\n",
    "            metrics.append(create_metrics_dict(check))\n",
    "        writer.writerow([\"\"]+checks)\n",
    "    \n",
    "        # True Positive Count\n",
    "        tpc= [\"True Positive Count\"]\n",
    "        for metric in metrics:\n",
    "            tpc.append(metric[\"tp\"])\n",
    "        writer.writerow(round_row(tpc))\n",
    "    \n",
    "        # False Positive Count\n",
    "        fpc= [\"False Positive Count\"]\n",
    "        for metric in metrics:\n",
    "            fpc.append(metric[\"fp\"])\n",
    "        writer.writerow(round_row(fpc))\n",
    "                        \n",
    "        # Precision\n",
    "        prec = [\"Precision\"]\n",
    "        for metric in metrics:\n",
    "            prec.append(metric[\"prec\"])\n",
    "        writer.writerow(round_row(prec))\n",
    "        \n",
    "        # Recall\n",
    "        recall = [\"Recall\"]\n",
    "        for metric in metrics:\n",
    "            recall.append(metric[\"recall\"])\n",
    "        writer.writerow(round_row(recall))\n",
    "\n",
    "        # Specificity\n",
    "        spec = [\"Specificity\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                spec.append(metric[\"tn\"]/(metric[\"tn\"]+metric[\"fp\"]))\n",
    "            except:\n",
    "                spec.append(\"N/A\")\n",
    "        writer.writerow(round_row(spec))\n",
    "    \n",
    "        # Miss Rate\n",
    "        miss = [\"Miss Rate\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                miss.append(metric[\"fn\"]/(metric[\"fn\"]+metric[\"tp\"]))\n",
    "            except:\n",
    "                miss.append(\"N/A\")\n",
    "        writer.writerow(round_row(miss))\n",
    "        \n",
    "        # False Positive Rate\n",
    "        fpr = [\"False Positive Rate\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                fpr.append(metric[\"fp\"]/(metric[\"fp\"]+metric[\"tn\"]))\n",
    "            except:\n",
    "                fpr.append(\"N/A\")\n",
    "        writer.writerow(round_row(fpr))\n",
    "    \n",
    "        # F1 Score\n",
    "        f1 = [\"F1 Score\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                f1.append((2*metric[\"prec\"]*metric[\"recall\"])/(metric[\"prec\"]+metric[\"recall\"]))\n",
    "            except:\n",
    "                f1.append(\"N/A\")\n",
    "        writer.writerow(round_row(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46655a4-04bd-4b0a-a069-fb0882df7967",
   "metadata": {},
   "source": [
    "The cell below will run analysis on all of the flags included in the list (the list can contain \"pii\", \"prompt_injection\", \"toxicity\", and/or \"sensitivity\"). **If any of these flags are not enabled in the Shield instance you are evaluating, omit it from the input list to avoid generating errors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dcbf8a-bb59-4b8e-b22f-d241fe06689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_analysis([\n",
    "    \"pii\",\n",
    "    \"prompt_injection\",\n",
    "    \"toxicity\",\n",
    "    \"sensitive_data\",\n",
    "    \"hallucination\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9157cc-3b1b-4a9d-9a75-b243a015436e",
   "metadata": {},
   "source": [
    "## iv. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08dbf4-3ebe-458e-80a0-b471763d54f9",
   "metadata": {},
   "source": [
    "Once you've finished with your testing, you can use the following cell to delete the test task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359dde28-0466-4d38-ad31-cf73d6e1d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_task(task_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
