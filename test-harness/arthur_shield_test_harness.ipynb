{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efac5cfd-12ec-4038-b9f7-1522ebd0e3e5",
   "metadata": {},
   "source": [
    "# Arthur Shield Test Harness\n",
    "\n",
    "The code below can be used to perform a test of the PII, Prompt Injection, Sensitivity, Toxicity, and Hallucination detection capabilities of Arthur Shield.\n",
    "\n",
    "### Pre-Requisites: \n",
    "- You will need to configure which checks you would like to perform within Arthur Shield. See https://shield.docs.arthur.ai/docs/rule-configuration-guide\n",
    "- You will need to compile a CSV file containing test prompts for each of the rules you would like to evaluate. You can reference the main template CSV in this folder for formatting, and use it to create your own list of prompts. The columns your input CSV should include are as follows (case-sensitive):\n",
    "    * *Non-hallucination checks*:\n",
    "        * *id* - A unique ID for the prompt\n",
    "        * *prompt* - The text you are sending to Shield that you would like to check\n",
    "        * *flag* - Which flag you expect this prompt to trigger. Must choose one of the following (ENUM): pii, prompt_injection, sensitive_data, toxicity, control\n",
    "    * *Hallucination checks*:\n",
    "        * *id* - A unique ID for the prompt\n",
    "        * *response* - The response from the LLM to be checked - should be mocked/pre-populated for this test\n",
    "        * *context* - The context which the response is supposed to be referencing\n",
    "        * *flag* - Which flag you expect this prompt to trigger. Must choose one of the following (ENUM): hallucination, control\n",
    "- **Notes for creating control prompts/responses**:\n",
    "  * *For non-hallucination checks*: In the `prompt` column, enter a simple prompt which will not violate any of the rules\n",
    "  * *For hallucination checks*: Provide context in the `context` column. In the `response` column, provide a response that only contains information that can be found within the context. Example below:\n",
    "    * `response`: \"The main export of Country X is textiles.\"\n",
    "    * `context`: \"Country X is known for its strong textile industry, which accounts for the majority of its exports.\"\n",
    "    * `flag`: control\n",
    "- Please aim to have at least 15 (and preferably more) prompts for each of the rules you would like to test in order to gather accurate analysis results, including controls\n",
    "\n",
    "### Output:\n",
    "This harness will output 2 CSVs: \n",
    "- Test output file containing info on the prompt, Shield flags, and latency\n",
    "- Metrics file containing various evaluation performance metrics for each of the Shield rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f346b-0779-4a53-ae23-6d9c6f22cbee",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "Fill out the config below with the details specific to your Shield instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a34cf7-fc8c-4209-8d8f-f932509bc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import shutil\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests \n",
    "from datetime import datetime\n",
    "\n",
    "from os.path import abspath, join\n",
    "import sys\n",
    "\n",
    "utils_path = abspath(join('..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "from shield_utils import setup_env, get_task, create_task_rule, archive_task\n",
    "\n",
    "load_dotenv()\n",
    "SHIELD_ENDPOINT = os.getenv('SHIELD_ENDPOINT', 'https://<your-shield-instance>') # Do not include the slash on the end\n",
    "SHIELD_API_KEY = os.getenv('SHIELD_API_KEY', '<your-shield-api-key>')\n",
    "\n",
    "# Change to whatever your input file names are\n",
    "PROMPT_1_PII_INPUT_FILE = 'data/hr_prompt_input_1_pii.csv'\n",
    "PROMPT_2_PROMPT_INJECTION_INPUT_FILE = 'data/hr_prompt_input_2_prompt_injection.csv'\n",
    "PROMPT_3_SENSITIVE_DATA_INPUT_FILE = 'data/hr_prompt_input_3_sensitive_data.csv'\n",
    "PROMPT_4_TOXICITY_INPUT_FILE = 'data/hr_prompt_input_4_toxicity.csv'\n",
    "PROMPT_5_CONTROL_INPUT_FILE = 'data/hr_prompt_input_5_control.csv'\n",
    "OUTPUT_FILE = 'output/shield_output_hr.csv'\n",
    "METRICS_FILE = 'output/shield_test_metrics_hr.csv'\n",
    "\n",
    "shield_headers = {\n",
    "    'Authorization': f'Bearer {SHIELD_API_KEY}'\n",
    "}\n",
    "\n",
    "setup_env(base_url=SHIELD_ENDPOINT, api_key=SHIELD_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473e252-857e-4516-8f41-d1ce9713ab12",
   "metadata": {},
   "source": [
    "You'll start by setting up a test task. If your Shield instance has default rules, the newly created task will automatically inherit those global rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d6bc3-011d-48ef-88e5-6bd33846f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ENDPOINT = f\"{SHIELD_ENDPOINT}/api/v2/task\"\n",
    "payload = {\"name\": \"test-harness\"}\n",
    "\n",
    "response = requests.post(TASK_ENDPOINT, headers=shield_headers, json=payload).json()\n",
    "task_id = response[\"id\"]\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20572e-9b63-4885-a895-ef6bf40d7258",
   "metadata": {},
   "source": [
    "#### Disable default rule(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ac373-d5ea-4114-a396-f2bb4bc91c7a",
   "metadata": {},
   "source": [
    "For the purpose of test harness, we will disable the default rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29239b-026f-4549-ba66-0e79b22ba123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_one_rule(task_id, rule_id):\n",
    "    endpoint = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/rules/{rule_id}\"\n",
    "    payload = {\"enabled\": \"false\"}\n",
    "    return requests.patch(endpoint, headers=shield_headers, json=payload)\n",
    "\n",
    "def enable_one_rule(task_id, rule_id):\n",
    "    endpoint = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/rules/{rule_id}\"\n",
    "    payload = {\"enabled\": \"true\"}\n",
    "    return requests.patch(endpoint, headers=shield_headers, json=payload)\n",
    "\n",
    "def disable_all_rules(task_id):\n",
    "    get_endpoint = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}\"\n",
    "    response = requests.get(get_endpoint, headers=shield_headers).json()\n",
    "    rule_ids=[]\n",
    "    for rule in response[\"rules\"]:\n",
    "        rule_ids.append(rule[\"id\"])\n",
    "    for rule_id in rule_ids:\n",
    "        disable_one_rule(task_id, rule_id)\n",
    "\n",
    "# Disable all rules from the test-harness task\n",
    "disable_all_rules(task_id)\n",
    "get_task(task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135f476-a03f-479b-9bf6-fd40b93155c3",
   "metadata": {},
   "source": [
    "#### Add new rules\n",
    "See https://shield.docs.arthur.ai/docs/rule-configuration-guide for rule setup instructions. Templates are provided below, but you can modify each of these rules as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa996d-3618-4941-a2c8-689d00f267ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pii = {\n",
    "  \"name\": \"Test PII Rule\",\n",
    "  \"type\": \"PIIDataRule\",\n",
    "  \"apply_to_prompt\": True,\n",
    "  \"apply_to_response\": False,\n",
    "  \"config\": {\n",
    "    \"disabled_pii_entities\": [\n",
    "      \"CRYPTO\",\n",
    "      \"DATE_TIME\",\n",
    "      \"CREDIT_CARD\",\n",
    "      \"IBAN_CODE\",\n",
    "      \"IP_ADDRESS\",\n",
    "      \"NRP\",\n",
    "      \"LOCATION\",\n",
    "      \"PERSON\",\n",
    "      \"MEDICAL_LICENSE\",\n",
    "      \"US_BANK_NUMBER\",\n",
    "      \"US_DRIVER_LICENSE\",\n",
    "      \"US_ITIN\",\n",
    "      \"US_PASSPORT\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "prompt_injection = {\n",
    "  \"name\": \"Test Prompt Injection Rule\",\n",
    "  \"type\": \"PromptInjectionRule\",\n",
    "  \"apply_to_prompt\": True,\n",
    "  \"apply_to_response\": False\n",
    "}\n",
    "toxicity = {\n",
    "  \"name\": \"Test Toxicity Rule\",\n",
    "  \"type\": \"ToxicityRule\",\n",
    "  \"apply_to_prompt\": True,\n",
    "  \"apply_to_response\": False\n",
    "}\n",
    "hallucination = {\n",
    "  \"name\": \"Test HallucinationV2 Rule\",\n",
    "  \"type\": \"ModelHallucinationRuleV2\",\n",
    "  \"apply_to_prompt\": False,\n",
    "  \"apply_to_response\": True\n",
    "}\n",
    "# You can reconfigure the sensitive data rule to your needs by providing positive/negative examples as shown below\n",
    "sensitive_data = { \n",
    "    \"name\": \"Test Sensitive Data Password Rule\",\n",
    "    \"type\": \"ModelSensitiveDataRule\",\n",
    "    \"apply_to_prompt\": True,\n",
    "    \"apply_to_response\": False,\n",
    "    \"config\": {\n",
    "      \"examples\": [\n",
    "        {\n",
    "          \"example\": \"We have prepared ASD research findings at https://needy-guilder.name. For access, use username Ashton_Langosh42 and password 9uZiNfpv9pr8.\",\n",
    "          \"result\": True\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Dear Members, the fund allocation data for the next fiscal year will be available on 11/10/1970. The password for the file is 2FDcCtK8ruY3.\",\n",
    "          \"result\": True\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Isom_Kling23, once again we require your assistance in revising the zoning laws for the Gwent. We have left the necessary documents and instructions on the FTP server. IP address: 97.167.207.127, login: Timmy_Wintheiser, password: RMvJ4UnmtMqk.\",\n",
    "          \"result\": True\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Hello Mrs. Stiedemann, our School Management App's credentials for Wilford.Schmitt are - Username: Theo.Abernathy58, Password: vDConKUVkCF3. Your association through this app will boost our endeavour for your ward's development.\",\n",
    "          \"result\": True\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Hi Miss Rippin, kindly confirm the transaction of £1,482.89 for your telemedicine consultation from your account number: 03433297.\",\n",
    "          \"result\": False\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"We are planning a server maintenance on 22th February at 0 and need to validate the connection to 197.54.143.140. Can you please assist with this?\",\n",
    "          \"result\": False\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Hello, This is your Family therapist. It is to notify that a payment is due for the last therapy session. This is payable via the link https://only-contract.com. Please use the credit card number 7307180895158036. The session cost is Дин.100.\",\n",
    "          \"result\": False\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Dear Dortha, due to a breach in our system, we advice you to immediately change your password (jkaWzJMMM9gK) for the online school portal.\",\n",
    "          \"result\": True\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Professor Marlowe, could you provide us with a lecture concerning the constitutional limitations in the realm of data privacy? In particular, touch upon how constitutional laws protect user data like passwords (e.g., Dte2bg0vfDXX) and credit card information (e.g., 2347580283766376, 209). We believe that your expertise would immensely benefit our students.\",\n",
    "          \"result\": True\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Dear Ms.Sigmund.Wehner67, all employees will need to change their passwords. Please make this update by 6 PM today. Spread the word in your Group. Contact us via 186.165.167.26 for any issues.\",\n",
    "          \"result\": False\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"The name tag for the new staff member, Angel has arrived. You will find it in the Apt. 634.\",\n",
    "          \"result\": False\n",
    "        },\n",
    "        {\n",
    "          \"example\": \"Hello Daphney, here are the coordinates [-49.3619,150.137] of your host family's place. Also, your secondary contact address will be Suite 747. Please keep this info safe.\",\n",
    "          \"result\": False\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6258f-29ee-4fde-ac20-8fc4e1124a7f",
   "metadata": {},
   "source": [
    "Once you've configured the rule settings, add them to the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb802b0-b620-4056-a8e5-afed30b00825",
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_rule = create_task_rule(task_id, pii)\n",
    "pii_rule_id = pii_rule.get('id')\n",
    "\n",
    "prompt_injection_rule = create_task_rule(task_id, prompt_injection)\n",
    "prompt_injection_rule_id = prompt_injection_rule.get('id')\n",
    "\n",
    "toxicity_rule = create_task_rule(task_id, toxicity)\n",
    "toxicity_rule_id = toxicity_rule.get('id')\n",
    "\n",
    "hallucination_rule = create_task_rule(task_id, hallucination)\n",
    "hallucination_rule_id = hallucination_rule.get('id')\n",
    "\n",
    "sensitive_data_rule = create_task_rule(task_id, sensitive_data)\n",
    "sensitive_data_rule_id = sensitive_data_rule.get('id')\n",
    "\n",
    "get_task(task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937a2a3-daa5-463d-b105-19a483540b37",
   "metadata": {},
   "source": [
    "Rules in Shield are immutable to maintain accurate validation result records. However, they can be deleted and recreated if modification is required.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d179b30-a4da-4295-84a3-7d1032257254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete one rule from the test-harness task\n",
    "def delete_one_rule(task_id, rule_id):\n",
    "    endpoint = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/rules/{rule_id}\"\n",
    "    return requests.delete(endpoint, headers=shield_headers)\n",
    "\n",
    "# Delete all rules from the test-harness task\n",
    "def delete_all_rules(task_id):\n",
    "    get_endpoint = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}\"\n",
    "    response = requests.get(get_endpoint, headers=shield_headers).json()\n",
    "    rule_ids=[]\n",
    "    for rule in response[\"rules\"]:\n",
    "        if(rule[\"scope\"] == \"task\"):\n",
    "            rule_ids.append(rule[\"id\"])\n",
    "    for rule_id in rule_ids:\n",
    "        delete_one_rule(task_id, rule_id)\n",
    "\n",
    "# delete_one_rule(task_id, <rule_id>)\n",
    "# delete_all_rules(task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421941e3-78c0-49d7-85f6-23dbc82da6f7",
   "metadata": {},
   "source": [
    "## i. Non-Hallucination Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd710ae-df76-4532-ab9d-ad294ffbe902",
   "metadata": {},
   "source": [
    "### Support Functions\n",
    "\n",
    "Shield's response schema can be found on the API docs: https://\\<your-shield-instance>/docs#/Default%20Validation/default_validate_prompt_api_v2_validate_prompt_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789476f-c80d-497e-b72f-6b1906adda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIELD_VAL_ENDPOINT = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/validate_prompt\"\n",
    "\n",
    "def get_firewall_flags(resp_dict):\n",
    "    # Determines which rules (PII, Prompt Injection, Toxicity, Sensitivity) were flagged\n",
    "    flags = []\n",
    "    for rule in resp_dict[\"rule_results\"]:\n",
    "        if rule[\"result\"] == \"Fail\":\n",
    "            if rule[\"rule_type\"] in [\"ModelHallucinationRuleV2\", \"ModelHallucionationRuleV3\"] and \"hallucination\" not in flags:\n",
    "                # Only used for responses - does not check for other flags\n",
    "                flags.append(\"hallucination\")\n",
    "                break\n",
    "            elif rule[\"rule_type\"] == \"PIIDataRule\" and \"pii\" not in flags:\n",
    "                flags.append(\"pii\")\n",
    "            elif rule[\"rule_type\"] == \"PromptInjectionRule\" and \"prompt_injection\" not in flags:\n",
    "                flags.append(\"prompt_injection\")\n",
    "            elif rule[\"rule_type\"] == \"ToxicityRule\" and \"toxicity\" not in flags:\n",
    "                flags.append(\"toxicity\")\n",
    "            elif rule[\"rule_type\"] == \"ModelSensitiveDataRule\" and \"sensitive_data\" not in flags:\n",
    "                flags.append(\"sensitive_data\")\n",
    "    return flags\n",
    "\n",
    "def get_gt_output_match(row):\n",
    "    # Returns True if GT label matches Shield flags and False otherwise\n",
    "    if row[\"ground_truth\"] == \"control\": \n",
    "        return False if row[\"shield_response\"] else True\n",
    "    else:\n",
    "        return True if row[\"ground_truth\"] in row[\"shield_response\"] else False\n",
    "    \n",
    "\n",
    "def get_pii_triggers(shield_response):\n",
    "    # Isolate the text which triggered the PII rule to fire\n",
    "    output = []\n",
    "    for rule in shield_response[\"rule_results\"]:\n",
    "        if rule[\"rule_type\"]== \"PIIDataRule\" and rule[\"result\"]==\"Fail\":\n",
    "            for flag in rule[\"details\"][\"pii_entities\"]:\n",
    "                output.append({\n",
    "                    \"string_trigger\": flag[\"span\"],\n",
    "                    \"flag_type\": flag[\"entity\"]\n",
    "                })\n",
    "    return output\n",
    "\n",
    "def get_shield_response(row):\n",
    "    # Calls Shield API and updates the row dictionary based upon the results from Shield\n",
    "    shield_start = datetime.now()\n",
    "    response = requests.post(SHIELD_VAL_ENDPOINT, headers=shield_headers, json={\"prompt\": row[\"prompt\"]})\n",
    "    shield_end = datetime.now()\n",
    "    row[\"latency_ms\"] = int((shield_end - shield_start).microseconds/1000)\n",
    "    row[\"shield_response\"] = get_firewall_flags(response.json())\n",
    "    row[\"gt_output_match\"] = get_gt_output_match(row)\n",
    "    row[\"sub_flags\"] = get_pii_triggers(response.json()) if \"pii\" in row[\"shield_response\"] else None\n",
    "    return row\n",
    "\n",
    "# Generate and append Shield response to the output file\n",
    "def append_shield_response(filename):\n",
    "    with open(filename, newline='') as infile:\n",
    "        reader= csv.DictReader(infile)\n",
    "        file_exists = os.path.isfile(OUTPUT_FILE)\n",
    "        with open(OUTPUT_FILE, 'a', newline='') as outfile:\n",
    "            # List of columns for the output file\n",
    "            fieldnames = [\n",
    "                \"id\",\n",
    "                \"prompt\",\n",
    "                \"ground_truth\",\n",
    "                \"shield_response\",\n",
    "                \"gt_output_match\",\n",
    "                \"sub_flags\",\n",
    "                \"latency_ms\"\n",
    "            ]\n",
    "            writer= csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            \n",
    "            for row in reader:\n",
    "                out_row = {\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"ground_truth\": row[\"flag\"],\n",
    "                    \"prompt\": row[\"prompt\"]\n",
    "                    }\n",
    "    \n",
    "                out_row = get_shield_response(out_row)\n",
    "                writer.writerow(out_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54eb91f-eb2e-4c52-a744-7d017c57285b",
   "metadata": {},
   "source": [
    "### Generate Output File\n",
    "\n",
    "The output file generated will contain: \n",
    "  * *id* - The ID of the corresponding input file prompt\n",
    "  * *prompt* - The prompt that was passed\n",
    "  * *ground_truth* - The flag that was expected\n",
    "  * *shield_response* - The flag that Shield raised\n",
    "  * *test_passed* - Whether the ground truth label matches the flag that Shield raised (True or False)\n",
    "  * *sub-flags* - (For PII) Which sentences were flagged and which PII flag was raised\n",
    "  * *latency_ms* - Latency of Shield call in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84df830-dd5c-4b22-a774-7f8255acc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous output files\n",
    "output_folder_name = \"output\"\n",
    "if os.path.exists(output_folder_name):\n",
    "    shutil.rmtree(output_folder_name)\n",
    "os.makedirs(output_folder_name)\n",
    "\n",
    "# Generate control input validation\n",
    "append_shield_response(PROMPT_5_CONTROL_INPUT_FILE)\n",
    "# Disable all rules to analyze one rule at a time\n",
    "disable_all_rules(task_id)\n",
    "\n",
    "# Generate PII validations\n",
    "enable_one_rule(task_id, pii_rule_id)\n",
    "append_shield_response(PROMPT_1_PII_INPUT_FILE)\n",
    "disable_one_rule(task_id, pii_rule_id)\n",
    "\n",
    "# Generate Promopt Injection validations\n",
    "enable_one_rule(task_id, prompt_injection_rule_id)\n",
    "append_shield_response(PROMPT_2_PROMPT_INJECTION_INPUT_FILE)\n",
    "disable_one_rule(task_id, prompt_injection_rule_id)\n",
    "\n",
    "# Generate sensitive data validations\n",
    "enable_one_rule(task_id, sensitive_data_rule_id)\n",
    "append_shield_response(PROMPT_3_SENSITIVE_DATA_INPUT_FILE)\n",
    "disable_one_rule(task_id, sensitive_data_rule_id)\n",
    "\n",
    "# Generate toxicity validations\n",
    "enable_one_rule(task_id, toxicity_rule_id)\n",
    "append_shield_response(PROMPT_4_TOXICITY_INPUT_FILE)\n",
    "disable_one_rule(task_id, toxicity_rule_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133da1da-4287-4585-b688-11ef3a0fd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(OUTPUT_FILE)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906f76e-2136-470d-bcf0-b27c700b4dd9",
   "metadata": {},
   "source": [
    "## ii. Hallucination Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d582a19-d93b-4cce-8323-f23ee0f9266a",
   "metadata": {},
   "source": [
    "The hallucination checks are for validating the LLM generated responses only and require a slightly different input format, so we run those checks separately here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665a268-efc2-4fd9-a3e8-57215b0b90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "HALLUCINATION_INPUT_FILE = 'data/hr_response_input_hallucination_and_control.csv' # Change this to whatever your input file name is \n",
    "HALLUCINATION_OUTPUT_FILE = 'output/shield_output_hallucination_hr.csv'\n",
    "\n",
    "SHIELD_RESP_ENDPOINT = f\"{SHIELD_ENDPOINT}/api/v2/tasks/{task_id}/validate_response/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1876a7-1304-4cf9-aa2e-0ed1693e49d9",
   "metadata": {},
   "source": [
    "### Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1400d-16ab-4c11-9490-e91b6bb73654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claims(response):\n",
    "    # Extracts the claims from the Shield flag \n",
    "    for rule in response[\"rule_results\"]:\n",
    "        if rule[\"rule_type\"] not in [\"ModelHallucinationRuleV2\", \"ModelHallucinationRuleV3\"]:\n",
    "            continue\n",
    "        else:\n",
    "            if rule[\"result\"] == \"Pass\":\n",
    "                return []\n",
    "            else:\n",
    "                return rule[\"details\"][\"claims\"]\n",
    "\n",
    "def get_inference_id(prompt):\n",
    "    # Conduct an initial Shield call to get an inference ID for the response endpoint\n",
    "    response = (requests.post(\n",
    "        SHIELD_VAL_ENDPOINT, \n",
    "        headers=shield_headers, \n",
    "        json={\"prompt\": prompt})).json()\n",
    "    return str(response[\"inference_id\"])\n",
    "        \n",
    "def get_hallucination_shield_response(row):\n",
    "    # Calls Shield API and updates the row dictionary based upon the results from Shield\n",
    "    resp_endpoint = SHIELD_RESP_ENDPOINT + get_inference_id(\"null\")\n",
    "    shield_start = datetime.now()\n",
    "    response = requests.post(\n",
    "        resp_endpoint, \n",
    "        headers=shield_headers, \n",
    "        json={\"response\": row[\"llm_response\"], \"context\": row[\"context\"]}\n",
    "    )\n",
    "    shield_end = datetime.now()\n",
    "    row[\"latency_ms\"] = int((shield_end - shield_start).microseconds/1000)\n",
    "    row[\"shield_response\"] = get_firewall_flags(response.json())\n",
    "    row[\"claims\"] = get_claims(response.json())\n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8147d-f600-4287-b0b4-0c48dd62f716",
   "metadata": {},
   "source": [
    "### Generate Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab0ca3-d1bf-426a-a94e-3ecdafeb62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_one_rule(task_id, hallucination_rule_id)\n",
    "with open(HALLUCINATION_INPUT_FILE, newline='') as infile:\n",
    "    reader= csv.DictReader(infile)\n",
    "    with open(HALLUCINATION_OUTPUT_FILE, 'w', newline='') as outfile:\n",
    "        # List of columns for the output file\n",
    "        fieldnames = [\n",
    "            \"id\",\n",
    "            \"context\",\n",
    "            \"llm_response\",\n",
    "            \"ground_truth\",\n",
    "            \"shield_response\",\n",
    "            \"claims\",\n",
    "            \"latency_ms\"\n",
    "        ]\n",
    "        writer= csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for row in reader:\n",
    "            out_row = {\n",
    "                \"id\": row[\"id\"],\n",
    "                \"llm_response\": row[\"response\"],\n",
    "                \"context\": row[\"context\"],\n",
    "                \"ground_truth\": row[\"flag\"]\n",
    "                }\n",
    "\n",
    "            out_row = get_hallucination_shield_response(out_row)\n",
    "            writer.writerow(out_row)\n",
    "disable_one_rule(task_id, hallucination_rule_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5988b7-9ad4-40ae-a4ee-ffee545e018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(HALLUCINATION_OUTPUT_FILE)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7593c-b3ac-4d3b-b529-a728dfa79bc5",
   "metadata": {},
   "source": [
    "## iii. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da0e84-18c5-4516-97e4-e60bb60c511b",
   "metadata": {},
   "source": [
    "The metrics file generated will contain:\n",
    "  * True Positive Count\n",
    "  * False Positive Count\n",
    "  * Precision\n",
    "  * Recall\n",
    "  * Specificity\n",
    "  * Miss Rate\n",
    "  * False Positive Rate\n",
    "  * F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbdd0f-9a68-459f-9fe8-b2a00f215757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_row(data_row, precision=3):\n",
    "    return [round(item, precision) if isinstance(item, (float, int)) else item for item in data_row]\n",
    "\n",
    "def create_metrics_dict(metric_name):\n",
    "    if metric_name == \"hallucination\":\n",
    "        hdf= pd.read_csv(HALLUCINATION_OUTPUT_FILE)\n",
    "        metrics = {\n",
    "            \"tp\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"hallucination\") & (hdf['shield_response'].apply(lambda x: metric_name in x))\n",
    "            ].shape[0],\n",
    "            \"fp\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"control\") & (hdf['shield_response'].apply(lambda x: metric_name in x))\n",
    "            ].shape[0],\n",
    "            \"fn\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"hallucination\") & (hdf['shield_response'].apply(lambda x: metric_name not in x))\n",
    "            ].shape[0],\n",
    "            \"tn\": hdf[\n",
    "            (hdf[\"ground_truth\"] == \"control\") & (hdf['shield_response'].apply(lambda x: metric_name not in x))\n",
    "            ].shape[0]\n",
    "        }\n",
    "    else:\n",
    "        df = pd.read_csv(OUTPUT_FILE)\n",
    "        metrics = {\n",
    "            \"tp\": df[(df['gt_output_match']==True) & (df['ground_truth']==metric_name)].shape[0],\n",
    "            \"fp\": df[(df['ground_truth']!=metric_name) & (df['shield_response'].apply(lambda x: metric_name in x))].shape[0],\n",
    "            \"fn\": df[(df['ground_truth']==metric_name) & (df['gt_output_match']==False)].shape[0],\n",
    "            \"tn\": df[(df['ground_truth']!=metric_name) & (df['shield_response'].apply(lambda x: metric_name not in x))].shape[0]\n",
    "        }\n",
    "    try:\n",
    "        metrics[\"prec\"] = metrics[\"tp\"]/(metrics[\"tp\"]+metrics[\"fp\"])\n",
    "    except: \n",
    "        metrics[\"prec\"] = \"N/A\"\n",
    "    try:\n",
    "        metrics[\"recall\"] = metrics[\"tp\"]/(metrics[\"tp\"]+metrics[\"fn\"])\n",
    "    except:\n",
    "        metrics[\"recall\"] = \"N/A\"\n",
    "    return metrics\n",
    "\n",
    "def run_analysis(checks=[\"pii\", \"prompt_injection\", \"toxicity\", \"sensitive_data\", \"hallucination\"]):\n",
    "    # Runs analysis on the selected checks. Runs on all by default\n",
    "    with open(METRICS_FILE, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        metrics = []\n",
    "        for check in checks:\n",
    "            metrics.append(create_metrics_dict(check))\n",
    "        writer.writerow([\"\"]+checks)\n",
    "    \n",
    "        # True Positive Count\n",
    "        tpc= [\"True Positive Count\"]\n",
    "        for metric in metrics:\n",
    "            tpc.append(metric[\"tp\"])\n",
    "        writer.writerow(round_row(tpc))\n",
    "    \n",
    "        # False Positive Count\n",
    "        fpc= [\"False Positive Count\"]\n",
    "        for metric in metrics:\n",
    "            fpc.append(metric[\"fp\"])\n",
    "        writer.writerow(round_row(fpc))\n",
    "                        \n",
    "        # Precision\n",
    "        prec = [\"Precision\"]\n",
    "        for metric in metrics:\n",
    "            prec.append(metric[\"prec\"])\n",
    "        writer.writerow(round_row(prec))\n",
    "        \n",
    "        # Recall\n",
    "        recall = [\"Recall\"]\n",
    "        for metric in metrics:\n",
    "            recall.append(metric[\"recall\"])\n",
    "        writer.writerow(round_row(recall))\n",
    "\n",
    "        # Specificity\n",
    "        spec = [\"Specificity\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                spec.append(metric[\"tn\"]/(metric[\"tn\"]+metric[\"fp\"]))\n",
    "            except:\n",
    "                spec.append(\"N/A\")\n",
    "        writer.writerow(round_row(spec))\n",
    "    \n",
    "        # Miss Rate\n",
    "        miss = [\"Miss Rate\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                miss.append(metric[\"fn\"]/(metric[\"fn\"]+metric[\"tp\"]))\n",
    "            except:\n",
    "                miss.append(\"N/A\")\n",
    "        writer.writerow(round_row(miss))\n",
    "        \n",
    "        # False Positive Rate\n",
    "        fpr = [\"False Positive Rate\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                fpr.append(metric[\"fp\"]/(metric[\"fp\"]+metric[\"tn\"]))\n",
    "            except:\n",
    "                fpr.append(\"N/A\")\n",
    "        writer.writerow(round_row(fpr))\n",
    "    \n",
    "        # F1 Score\n",
    "        f1 = [\"F1 Score\"]\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                f1.append((2*metric[\"prec\"]*metric[\"recall\"])/(metric[\"prec\"]+metric[\"recall\"]))\n",
    "            except:\n",
    "                f1.append(\"N/A\")\n",
    "        writer.writerow(round_row(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46655a4-04bd-4b0a-a069-fb0882df7967",
   "metadata": {},
   "source": [
    "The cell below will run analysis on all of the flags included in the list (the list can contain \"pii\", \"prompt_injection\", \"toxicity\", and/or \"sensitivity\"). **If any of these flags are not enabled in the Shield instance you are evaluating, omit it from the input list to avoid generating errors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dcbf8a-bb59-4b8e-b22f-d241fe06689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_analysis([\n",
    "    \"pii\",\n",
    "    \"prompt_injection\",\n",
    "    \"toxicity\",\n",
    "    \"sensitive_data\",\n",
    "    \"hallucination\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9157cc-3b1b-4a9d-9a75-b243a015436e",
   "metadata": {},
   "source": [
    "## iv. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08dbf4-3ebe-458e-80a0-b471763d54f9",
   "metadata": {},
   "source": [
    "Once you've finished with your testing, you can use the following cell to delete the test task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359dde28-0466-4d38-ad31-cf73d6e1d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_task(task_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
