{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallucination Rule Demonstration Notebook\n",
    "\n",
    "In this notebook we will walk through the following steps in order to demonstrate what the Shield Hallucination Rule is capable of.\n",
    "\n",
    "- Hallucination detected.\n",
    "- No hallucination detected. \n",
    "- Not evaluated for hallucinaion.\n",
    "\n",
    "Pre  Requisites: \n",
    "- A Shield env and API key.\n",
    "\n",
    "1. Create a new task for Hallucination evaluation \n",
    "2. Arthur Benchmark dataset evaluation \n",
    "   1. Run the examples against a pre-configured Shield task from Step 1 \n",
    "   2. View our results \n",
    "3. Additional examples evaluation using datasets referenced in our documentation: https://shield.docs.arthur.ai/docs/hallucination#benchmarks\n",
    "   1. Run the examples against a pre-configured Shield task from Step 1 \n",
    "    2. View our results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Shield Test Env Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/homebrew/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /Users/calebsarnecki/Library/Python/3.11/lib/python/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/calebsarnecki/Library/Python/3.11/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (3.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Setup against: http://127.0.0.1:8000/api/v2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install scikit-learn\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "from os.path import abspath, join\n",
    "import sys\n",
    "import random\n",
    "\n",
    "utils_path = abspath(join('..', 'utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "from shield_utils import create_task_rule, task_prompt_validation, archive_task_rule, get_task, create_task, task_response_validation, setup_env\n",
    "from analysis_utils import print_performance_metrics, granular_result_dfs\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "setup_env(base_url=\"<URL>\", api_key=\"<API_KEY>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.Setup: Configure a test task and enable Prompt Injection Rule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8000/api/v2\n",
      "{'id': '9f3737b0-395c-4420-81d1-b56851d983d4', 'name': 'Hallucination Rule', 'type': 'ModelHallucinationRuleV2', 'apply_to_prompt': False, 'apply_to_response': True, 'enabled': True, 'scope': 'task', 'created_at': 1711732552481, 'updated_at': 1711732552481, 'config': None}\n",
      "{'id': '276c85b0-55f1-48a1-bcb2-cb5d6d806df8', 'name': 'hallucination-test-task-2257', 'created_at': 1711732552332, 'updated_at': 1711732552332, 'rules': [{'id': '9f3737b0-395c-4420-81d1-b56851d983d4', 'name': 'Hallucination Rule', 'type': 'ModelHallucinationRuleV2', 'apply_to_prompt': False, 'apply_to_response': True, 'enabled': True, 'scope': 'task', 'created_at': 1711732552481, 'updated_at': 1711732552481, 'config': None}]}\n"
     ]
    }
   ],
   "source": [
    "hallucination_rule_config =  {\n",
    "    \"name\": \"Hallucination Rule\",\n",
    "    \"type\": \"ModelHallucinationRuleV2\",\n",
    "    \"apply_to_prompt\": False,\n",
    "    \"apply_to_response\": True\n",
    "}\n",
    "\n",
    "# 1 - Create Task \n",
    "random_number = random.randint(1, 10000)\n",
    "task_name = f\"hallucination-test-task-{random_number}\"\n",
    "hallucination_task = create_task(task_name)\n",
    "hallucination_task_id = hallucination_task[\"id\"]\n",
    "\n",
    "# 2 - Disable all rules (if there any default)\n",
    "for rule in hallucination_task[\"rules\"]:\n",
    "    archive_task_rule(hallucination_task[\"id\"], rule[\"id\"])\n",
    "\n",
    "# 3 - Create Rule \n",
    "hallucination_rule = create_task_rule(task_id=hallucination_task[\"id\"], rule_config=hallucination_rule_config)\n",
    "\n",
    "print(hallucination_rule)\n",
    "hallucination_task = get_task(hallucination_task_id)\n",
    "print(hallucination_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Arthur benchmark dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_benchmark_df_arthur = pd.read_csv(\"./arthur_benchmark_datasets/hallucination_benchmark_dummy.csv\")\n",
    "\n",
    "hallucination_benchmark_df_arthur['label'] = hallucination_benchmark_df_arthur['binary_label'].map({0: False, 1: True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1  Run the examples against a pre-configured Shield task from Step 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid task {'id': '276c85b0-55f1-48a1-bcb2-cb5d6d806df8', 'name': 'hallucination-test-task-2257', 'created_at': 1711732552332, 'updated_at': 1711732552332, 'rules': [{'id': '9f3737b0-395c-4420-81d1-b56851d983d4', 'name': 'Hallucination Rule', 'type': 'ModelHallucinationRuleV2', 'apply_to_prompt': False, 'apply_to_response': True, 'enabled': True, 'scope': 'task', 'created_at': 1711732552481, 'updated_at': 1711732552481, 'config': None}]}\n",
      "Fail\n",
      "Pass\n",
      "Fail\n"
     ]
    }
   ],
   "source": [
    "if (len(hallucination_task[\"rules\"]) > 1):\n",
    "    raise Exception(\"Cannot have more than one rule enabled for this test.\")\n",
    "else: \n",
    "    if hallucination_task[\"rules\"][0][\"type\"] != \"ModelHallucinationRuleV2\":\n",
    "            raise Exception(\"Invalid rule type enabled. Must be PromptInjectionRule.\")\n",
    "    else: \n",
    "         print(f\"Valid task {hallucination_task}\")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "task_id = hallucination_task[\"id\"]\n",
    "\n",
    "def shield_hallucination_evaluation(row): \n",
    "    shield_prompt_inference = task_prompt_validation(\"dummy\", 1, task_id)\n",
    "\n",
    "    inference_id = shield_prompt_inference[\"inference_id\"]\n",
    "\n",
    "    shield_result = task_response_validation(row.text, row.context, inference_id, task_id)\n",
    "\n",
    "    # TODO - add the reason or claims breakdown \n",
    "    \n",
    "    for rule_result in shield_result[\"rule_results\"]:\n",
    "        if rule_result[\"id\"] == hallucination_rule[\"id\"]:\n",
    "            result = rule_result[\"result\"]\n",
    "\n",
    "            print(result)\n",
    "            if result == \"Pass\": \n",
    "                result = False\n",
    "            else:\n",
    "                result = True\n",
    "\n",
    "            return result\n",
    "        \n",
    "\n",
    "hallucination_benchmark_df_arthur[\"shield_result\"] = hallucination_benchmark_df_arthur.apply(shield_hallucination_evaluation, axis=1).apply(pd.Series)\n",
    "\n",
    "# # Save to CSV to avoid having to run this again to view results \n",
    "hallucination_benchmark_df_arthur.to_csv(f\"./results/hallucination_benchmark_df_arthur_{current_datetime}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Confusion Matrix:\n",
      "[[TN FP] \n",
      " [FN TP]] \n",
      "[[1 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "print_performance_metrics(hallucination_benchmark_df_arthur)\n",
    "\n",
    "arthur_fn, arthur_fp, arthur_tp, arthur_tn = granular_result_dfs(hallucination_benchmark_df_arthur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Load benchmark datasets from https://shield.docs.arthur.ai/docs/hallucination#benchmarks\n",
    "\n",
    "**DISCLAIMER**: This is for demonstration and guidance purposes only and does not reflect the performance of the model behind the Shield score, as sampling techniques may not be optimal. \n",
    "**DISCLAIMER 2**: This dataset contains German and Arthur prompt injection is only trained on English. We do our best to filter it out, but some German may slip through. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1  Run the examples against a pre-configured Shield task from Step 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Analyze Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
